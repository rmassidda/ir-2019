# Posting list compression

Given that the postings are encoded as integers it's a good idea to encode small numbers in less space than large numbers, this situation is furthermore very common if the posting list is preprocessed via gap-encoding.

The $\gamma$-code is a universal code for integers which uses a fixed model.
Given an integer $x$ and $L$ the length of its optimal representation $B(x)$, $x$ is represented as a binary sequence composed of two parts: a sequence of $L-1$ zero, followed by the binary representation $B(x)$.
The decoding is easy, count the $c$ consecutive number of zeros up to the first $1$, then fetch the following $c+1$ characters and interpret the sequence as the integer $x$.

PForDelta code is a method that supports extremely fast decompression and achieves a small size in the compressed output whenever the values follow a Gaussian distribution.
Fixed $a,b>0$, all the integers in the interval $[a,a+2^b-1]$ are encoded with $b$ bits by translating them in the interval $[0,2^b-1]$, all the other integers are instead prefixed with $b$ $1$ bits before a standard integer representation.
The encoding does not occur in streaming, but instead the $b$ bytes ones are used as an escape symbol for the explicit coded integers, stored in another partition.
The value $b$ is a trade-off, for bigger values there will be less elements in the "extra values" partition,  but the "normal" partition size is increased.

In the $t$-nibble code, the binary representation $B(x)$ is left-padded with zeros up to the minimum  number of bits multiple of $t-1$.
Then groups of $t$ bits are generated by dividing the intermediate representation in buckets of $t-1$ bits, prefixing with $1$ the first bucket and with $0$ all the other.
Given a sequence of bits, the decompression only require to scan shifting of $t$ bits, concatenating the intermediate bits.
The so called variable-byte code is a specialization of $t$-nibble, with $t = 8$.

The Elias-Fano code requires that the elements are strictly increasing, so the posting list must be explicitly kept and can't be gap-encoded.
Fixed $n$ the number of integers, $m$ as the value of the maximum number plus one, we can compute $z = \log_2 n$ and $w = \log_2 \frac{m}{n}$.
For each integer represented in $z+w$ bits the last $w$ bits are concatenated in a list $L$, so $|L| = nw = n \log \frac{m}{n}$.
The $z$ remaining bits can possibly have $2^z$ representations, we then construct another sequence $H$ by counting the occurrences of each representation in a negative unary[^2] representation, so $|H| = 2^z + n$.
Overall the cost of the representation is $|L|+|H|= n(2+\log\frac{m}{n})$, wasting only two bits per number respect to the optimal code.

There exist data structures able to decompress numbers in constant time.
We propose instead the following algorithm to get the $k$-th number of the list:

- Set $r$ as the number of $0$ bits up to the $k$-th $1$ bit in $H$
- Get the $k$-th group of bits in $L$
- The value of the integer is the concatenation of the $r$-th prefix representation and the group of bits found in $L$.

[^2]: The negative unary representation of a number consist in the repetition a 1 per unit, terminated by a 0. That is 0, 10, 110, 1110, ...
